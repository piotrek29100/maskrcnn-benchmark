{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WARNING: maskrcnn_benchmark.config load global variables - in case of RuntimeError: Error(s) in loading state_dict for GeneralizedRCNN: size mismatch (...) try restart kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"tables\"\n",
    "model_index = f\"2019_06_06_{model_type}\"\n",
    "#model_output_dir = \"./output/chata/2019_05_15_charts\" # directory with model checkpoints\n",
    "model_output_dir = f\"./output/chata/2019_05_15_{model_type}\" # directory with model checkpoints\n",
    "#model_output_dir = \"./\"\n",
    "\n",
    "if model_type==\"charts\":\n",
    "    config_file_type = \"chata\"\n",
    "    correct_label = 2\n",
    "elif model_type==\"tables\":\n",
    "    config_file_type = \"tables\"\n",
    "    correct_label = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "\n",
    "import importlib\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from demo.predictor_chata import ChataDemo\n",
    "from demo.predictor import COCODemo\n",
    "\n",
    "import maskrcnn_benchmark.config as config\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this makes our figures bigger\n",
    "pylab.rcParams['figure.figsize'] = 20, 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    plt.imshow(img[:, :, [2, 1, 0]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(url):\n",
    "    \"\"\"\n",
    "    Given an url of an image, downloads the image and\n",
    "    returns a PIL image\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    pil_image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "    # convert to BGR format\n",
    "    image = np.array(pil_image)[:, :, [2, 1, 0]]\n",
    "    return image\n",
    "\n",
    "def imshow(img):\n",
    "    plt.imshow(img[:, :, [2, 1, 0]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this makes our figures bigger\n",
    "pylab.rcParams['figure.figsize'] = 20, 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maskrcnn_benchmark.data.datasets.chata import ChataDataset, TablesDataset\n",
    "import imageio as imio\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"train\", \"test\", \"val\"\n",
    "if model_type==\"charts\":\n",
    "    dataset = ChataDataset(\"./datasets/chata/chata\", \"val\")\n",
    "elif model_type==\"tables\":\n",
    "    dataset = TablesDataset(\"./datasets/chata/tables\", \"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_filter(img):\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    #plt.imshow(img, cmap='gray', vmin=0, vmax=255)\n",
    "        \n",
    "    threshold, img = cv.threshold(img, 0, 255, cv.THRESH_OTSU)\n",
    "    #plt.imshow(img, cmap='gray', vmin=0, vmax=255)\n",
    "        \n",
    "    img = cv.distanceTransform(img, cv.DIST_L1, 0)\n",
    "    #plt.imshow(img, cmap='gray', vmin=0, vmax=255)\n",
    "        \n",
    "    img = cv.cvtColor(img, cv.COLOR_GRAY2BGR)\n",
    "    img = img.astype(np.uint8)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model_index, chata_demo, dataset, dataset_type=\"val\", img_range=(0,5)):\n",
    "    \n",
    "    os.makedirs(f\"chata_results/{model_index}_samples\", exist_ok=True)\n",
    "    predictions = []\n",
    "    groundtruth = []\n",
    "    labels = []\n",
    "    for i in range(*img_range):\n",
    "        test_img = np.array(dataset.__getitem__(i)[0])\n",
    "        result, top_predictions = chata_demo.run_on_opencv_image(test_img)\n",
    "        #imio.imwrite(f'chata_results/{model_index}_samples/{dataset_type}_{i:2d}.jpg', result)\n",
    "        predictions.append(top_predictions)\n",
    "        groundtruth.append(np.array(dataset.__getitem__(i)[1].bbox)[0])\n",
    "        labels.append(dataset.__getitem__(0)[1].get_field(\"labels\"))\n",
    "        \n",
    "    return predictions, groundtruth, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from ./output/chata/2019_05_15_tables/model_final.pth\n",
      "[Checkpointer._load_file] Model loading: ./output/chata/2019_05_15_tables/model_final.pth\n"
     ]
    }
   ],
   "source": [
    "config_file = f\"./configs/chata/e2e_faster_rcnn_R_50_C4_1x_1_gpu_voc_{config_file_type}.yaml\"\n",
    "config.cfg.merge_from_file(config_file)\n",
    "config.cfg.merge_from_list([\"MODEL.DEVICE\", \"cpu\"])\n",
    "config.cfg.merge_from_list([\"OUTPUT_DIR\", model_output_dir])\n",
    "\n",
    "chata_demo = ChataDemo(\n",
    "    config.cfg,\n",
    "    model_type,\n",
    "    min_image_size=800,\n",
    "    confidence_threshold=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions, groundtruth, labels = predict(model_index, chata_demo, dataset, \"val\", (0,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(0,0) = top_left_corner\n",
    "#xyxy - top_left, bottom_right \n",
    "def get_box_area(box):\n",
    "    y_diff = box[3]-box[1]\n",
    "    x_diff = box[2]-box[0]\n",
    "    if y_diff<=0 or x_diff<=0:\n",
    "        return 0\n",
    "    \n",
    "    return x_diff * y_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert get_box_area([2,1,4,3]) == 4\n",
    "assert get_box_area([1,2,3,4]) == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boxes_common_area(box1, box2):\n",
    "    x1 = np.maximum(box1[0], box2[0])\n",
    "    y1 = np.maximum(box1[1], box2[1])\n",
    "    x2 = np.minimum(box1[2], box2[2])\n",
    "    y2 = np.minimum(box1[3], box2[3])\n",
    "    return get_box_area([x1,y1,x2,y2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "assert get_boxes_common_area([2,1,4,3], [1,2,3,4]) == 1\n",
    "assert get_boxes_common_area([2,1,4,3], [0,0,4,4]) == 4\n",
    "assert get_boxes_common_area([0,0,1,1], [1,1,2,2]) == 0\n",
    "assert get_boxes_common_area([0,0,1,1], [6,9,9,15]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(0,0) = top_left_corner\n",
    "#xyxy - top_left, bottom_right \n",
    "def IoU(box, box_pred):\n",
    "    common_area = get_boxes_common_area(box, box_pred)\n",
    "    box_area = get_box_area(box)\n",
    "    box_pred_area = get_box_area(box_pred)\n",
    "    \n",
    "    return common_area / (box_area+box_pred_area-common_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou = []\n",
    "for i in range(len(predictions)):\n",
    "    image_predictions = predictions[i]\n",
    "    box = groundtruth[i]\n",
    "    label = labels[i]\n",
    "    if label!=correct_label:\n",
    "        continue\n",
    "    if len(image_predictions.bbox) == 0:\n",
    "        iou.append(-1)\n",
    "    else:\n",
    "        label = image_predictions.get_field(\"labels\")\n",
    "        score = image_predictions.get_field(\"scores\")\n",
    "        pred_box = image_predictions.bbox[0]\n",
    "        \n",
    "        if label[0]==correct_label:\n",
    "            result = IoU(box, np.array(pred_box))\n",
    "            iou.append(result)\n",
    "        else:\n",
    "            iou.append(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou = np.array(iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iou array\n",
    "# >0 - iou score\n",
    "# (-1) - no prediction\n",
    "# (-2) - predicted other object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.79812461,  0.46922365,  0.33291793, -1.        , -1.        ,\n",
       "        0.89150119,  0.70695841,  0.82276833,  0.57117981, -1.        ,\n",
       "        0.77590674,  0.34555846,  0.13867702, -1.        , -1.        ,\n",
       "        0.76271766,  0.90269619,  0.78698009,  0.88211757,  0.35490149])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision + recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(results):\n",
    "    for threshold in [0.6,0.7,0.8,0.9]:\n",
    "        precision = np.sum(results>=threshold) / np.sum(results>=0)\n",
    "        recall = np.sum(results>=threshold) / len(results)\n",
    "        f1_score = 2*precision*recall/(precision+recall)\n",
    "        print(f\"Threshold={threshold:.2f}; Precision={precision:.3f}; Recall={recall:.3f}; F1 score: {f1_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold=0.60; Precision=0.455; Recall=0.455; F1 score: 0.455\n",
      "Threshold=0.70; Precision=0.364; Recall=0.364; F1 score: 0.364\n",
      "Threshold=0.80; Precision=0.273; Recall=0.273; F1 score: 0.273\n",
      "Threshold=0.90; Precision=0.182; Recall=0.182; F1 score: 0.182\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(np.array([i/10 for i in range(0,11)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold=0.60; Precision=0.455; Recall=0.312; F1 score: 0.370\n",
      "Threshold=0.70; Precision=0.364; Recall=0.250; F1 score: 0.296\n",
      "Threshold=0.80; Precision=0.273; Recall=0.188; F1 score: 0.222\n",
      "Threshold=0.90; Precision=0.182; Recall=0.125; F1 score: 0.148\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(np.array([i/10 for i in range(0,11)] + [-1,-2,-1,-2,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold=0.60; Precision=0.600; Recall=0.450; F1 score: 0.514\n",
      "Threshold=0.70; Precision=0.600; Recall=0.450; F1 score: 0.514\n",
      "Threshold=0.80; Precision=0.267; Recall=0.200; F1 score: 0.229\n",
      "Threshold=0.90; Precision=0.067; Recall=0.050; F1 score: 0.057\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(iou)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example\n",
    "img = cv.imread('cTDaR_t10260.png')\n",
    "img = apply_filter(img)\n",
    "imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('cTDaR_t10260.png')\n",
    "prediction = chata_demo.run_on_opencv_image(img)\n",
    "imshow(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_loss(date, dataset_type=\"val\", log_path=None):\n",
    "    os.makedirs(f\"./output/chata/{model_index}\", exist_ok=True)\n",
    "    os.makedirs(f\"./chata_results/{model_index}\", exist_ok=True)\n",
    "    if log_path is None:\n",
    "        log_path = f\"./output/chata/{model_index}/log.txt\"\n",
    "    with open(log_path) as file:\n",
    "        logs = file.read()\n",
    "\n",
    "        for loss_type in [\"loss\", \"loss_classifier\", \"loss_box_reg\", \"loss_objectness\", \"loss_rpn_box_reg\"]:\n",
    "            loss = re.findall(f\"{loss_type}: [0-9]*.[0-9]* \\([0-9]*.[0-9]*\", logs)\n",
    "            loss = [x[len(loss_type)+2:] for x in loss]\n",
    "            \n",
    "            iterations = re.findall(f\"iter: [0-9]*\", logs)\n",
    "            iterations = [int(x[6:]) for x in iterations]\n",
    "            \n",
    "            plt.plot(iterations, [float(x.split(\"(\")[0]) for x in loss])\n",
    "            plt.plot(iterations, [float(x.split(\"(\")[1]) for x in loss])\n",
    "            plt.title(loss_type.upper())\n",
    "            plt.xlabel('Iteration', fontsize=14)\n",
    "            plt.ylabel('Loss value', fontsize=14)\n",
    "            plt.savefig(f\"./chata_results/{date}/{dataset_type}_{loss_type}.png\")\n",
    "            plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_loss(model_index, \"val\", \"./log.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on real dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_names = os.listdir(\"chata_results/images\")\n",
    "catalogs = [f\"chata_results/images/{name}\" for name in catalog_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: {}\n",
      "Labels: {'table': 0.5912390351295471}\n",
      "Labels: {}\n",
      "Labels: {'table': 0.7189908027648926}\n",
      "Labels: {}\n",
      "Labels: {'table': 0.9999996423721313}\n",
      "Labels: {'table': 0.99920254945755}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {'table': 0.68449467420578}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {'table': 0.9499477744102478}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {'table': 0.9999972581863403}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {'table': 0.9999815225601196}\n",
      "Labels: {}\n",
      "Labels: {'table': 0.7795243859291077}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {'table': 0.9999988079071045}\n",
      "Labels: {}\n",
      "Labels: {'table': 0.5679640173912048}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {}\n",
      "Labels: {'table': 0.9999827146530151}\n"
     ]
    }
   ],
   "source": [
    "for catalog in catalogs:\n",
    "    os.makedirs(f'{catalog}/{model_index}', exist_ok=True)\n",
    "    for img_name in os.listdir(catalog):\n",
    "        if \"png\" in img_name:\n",
    "            test_img = cv2.imread(f\"{catalog}/{img_name}\")\n",
    "            test_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)\n",
    "            #imshow(test_img)\n",
    "            prediction = chata_demo.run_on_opencv_image(test_img)\n",
    "            imio.imwrite(f'{catalog}/{model_index}/{img_name}', prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rcnn]",
   "language": "python",
   "name": "conda-env-rcnn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
